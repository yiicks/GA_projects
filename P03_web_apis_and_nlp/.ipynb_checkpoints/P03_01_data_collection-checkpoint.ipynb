{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398f4f25",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & NLP\n",
    "### Notebook 1: Introduction and Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a9132",
   "metadata": {},
   "source": [
    "### Introduction & Problem Statement\n",
    "As a Redditor and data aficionado, train a classifier to tell two sub-reddits apart using evaluation metrics (below):\n",
    "- `r/jobs`, which focuses more on immediate issues and getting a job, and \n",
    "- `r/careerguidance`, which focuses more on longer-term (career) decisions.\n",
    "\n",
    "#### Context\n",
    "Administrators and moderators for these sub-reddits have a partnership to develop a feature to suggest to users to in which subreddit to post their content. This feature will simply take their content (`selftext`) and evaluate where their post belongs.\n",
    "\n",
    "There is some active moderation which results in post removals. Moderation policy is less clearly written out for the `r/careerguidance` subreddit.\n",
    "- [Moderation Policy for r/jobs](https://www.reddit.com/r/jobs/wiki/policy)\n",
    "- [Modpost for r/careerguidance](https://www.reddit.com/r/careerguidance/comments/fwdma6/new_post_requirement_please_use_location_flairs/)\n",
    "\n",
    "Caveat: Context is fictional. :)\n",
    "\n",
    "#### Evaluation & metrics\n",
    "The cost of misclassification is that the feature being developed would misplace the post, meaning more work for moderators. As a classification model, we look at not just accuracy, but also precision and recall. As there is no distinct reason to prioritize either precision or recall, we will focus on the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3f7bcf",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "Scape **posts** using Pushshift's API, then use NLP to discern investing advice between two investment-related sub-reddits: \n",
    "- [r/jobs](https://www.reddit.com/r/jobs/) and\n",
    "- [r/careerguidance](https://www.reddit.com/r/careerguidance/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479c9193",
   "metadata": {},
   "source": [
    "### Notebook organization:\n",
    "1. Introduction and scraping (**CURRENT**: Generate raw datasets)\n",
    "2. [Data Cleaning and Exploratory Data Analysis (EDA)](./P03_02_data_cleaning_and_eda.ipynb) (Generate cleaned datasets)\n",
    "3. [Pre-processing, modelling, assessments and conclusions](./P03_03_modelling_and_conclusions.ipynb) (Pre-processing, model, evaluate and summarize conclusions & recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6581597",
   "metadata": {},
   "source": [
    "### Sub-reddit scraping\n",
    "This notebook will focus data collection via sub-reddit data scraping. \n",
    "\n",
    "It will then generate relevant `.csv` files for use in later notebooks as raw datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd6b81",
   "metadata": {},
   "source": [
    "#### On the API used\n",
    "Related reference (Pushshift API parameters): https://pushshift.io/api-parameters/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba981cd",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2bd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cdbf45",
   "metadata": {},
   "source": [
    "#### Scaping via Reddit Pushshift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a310e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subreddits to scrape\n",
    "subreddit_1 = 'jobs'\n",
    "subreddit_2 = 'careerguidance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb6f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping function for subreddit\n",
    "# 2 batches scraped as default\n",
    "def scrape(subreddit, filepath, batches=2):\n",
    "    # initialize\n",
    "    url = f'https://api.pushshift.io/reddit/search/submission/'\n",
    "    posts = []\n",
    "    # base API parameters\n",
    "    params = {\n",
    "        'subreddit': subreddit,\n",
    "        'size': 100\n",
    "    }\n",
    "    last_time_stamp = None\n",
    "    # iteratively scrape\n",
    "    for i in range(batches):\n",
    "        if i != 0:\n",
    "            params['before'] = last_time_stamp\n",
    "        res = requests.get(url, params)\n",
    "        data = res.json()\n",
    "        print(f'{subreddit} run {i+1}, status code={res.status_code}; time={last_time_stamp}')\n",
    "        last_time_stamp = data['data'][-1]['created_utc']\n",
    "        posts.extend(data['data'])\n",
    "    pd.DataFrame(posts)[['title','subreddit','selftext']].to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ae2258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs run 1, status code=200; time=None\n",
      "jobs run 2, status code=200; time=1642527361\n",
      "jobs run 3, status code=200; time=1642486680\n",
      "jobs run 4, status code=200; time=1642454745\n",
      "jobs run 5, status code=200; time=1642408353\n",
      "jobs run 6, status code=200; time=1642359611\n",
      "jobs run 7, status code=200; time=1642298081\n",
      "jobs run 8, status code=200; time=1642262178\n",
      "jobs run 9, status code=200; time=1642203542\n",
      "jobs run 10, status code=200; time=1642172473\n",
      "jobs run 11, status code=200; time=1642129249\n",
      "jobs run 12, status code=200; time=1642102930\n",
      "jobs run 13, status code=200; time=1642068485\n",
      "jobs run 14, status code=200; time=1642026591\n",
      "jobs run 15, status code=200; time=1642006517\n",
      "jobs run 16, status code=200; time=1641964815\n",
      "jobs run 17, status code=200; time=1641940698\n",
      "jobs run 18, status code=200; time=1641914472\n",
      "jobs run 19, status code=200; time=1641869817\n",
      "jobs run 20, status code=200; time=1641844563\n",
      "jobs run 21, status code=200; time=1641803802\n",
      "jobs run 22, status code=200; time=1641756882\n",
      "jobs run 23, status code=200; time=1641695580\n",
      "jobs run 24, status code=200; time=1641654734\n",
      "jobs run 25, status code=200; time=1641598386\n",
      "careerguidance run 1, status code=200; time=None\n",
      "careerguidance run 2, status code=200; time=1642529323\n",
      "careerguidance run 3, status code=200; time=1642482123\n",
      "careerguidance run 4, status code=200; time=1642450009\n",
      "careerguidance run 5, status code=200; time=1642408603\n",
      "careerguidance run 6, status code=200; time=1642365752\n",
      "careerguidance run 7, status code=200; time=1642301700\n",
      "careerguidance run 8, status code=200; time=1642249311\n",
      "careerguidance run 9, status code=200; time=1642189981\n",
      "careerguidance run 10, status code=200; time=1642138632\n",
      "careerguidance run 11, status code=200; time=1642104478\n",
      "careerguidance run 12, status code=200; time=1642077331\n",
      "careerguidance run 13, status code=200; time=1642024819\n",
      "careerguidance run 14, status code=200; time=1641996717\n",
      "careerguidance run 15, status code=200; time=1641948465\n",
      "careerguidance run 16, status code=200; time=1641921530\n",
      "careerguidance run 17, status code=200; time=1641877753\n",
      "careerguidance run 18, status code=200; time=1641845943\n",
      "careerguidance run 19, status code=200; time=1641811710\n",
      "careerguidance run 20, status code=200; time=1641761890\n",
      "careerguidance run 21, status code=200; time=1641710582\n",
      "careerguidance run 22, status code=200; time=1641667596\n",
      "careerguidance run 23, status code=200; time=1641627502\n",
      "careerguidance run 24, status code=200; time=1641579658\n",
      "careerguidance run 25, status code=200; time=1641528884\n",
      "Wall time: 6min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# initialize session\n",
    "with requests.Session() as s:\n",
    "    # scrape first subreddit\n",
    "    scrape(subreddit_1,\n",
    "           filepath='./data/subreddit_1_raw.csv',\n",
    "           batches=25)\n",
    "    # scrape second subreddit\n",
    "    scrape(subreddit_2,\n",
    "           filepath='./data/subreddit_2_raw.csv',\n",
    "           batches=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
